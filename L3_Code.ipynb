{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browsing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing a directory with `os.listdir`\n",
    "import os\n",
    "\n",
    "files = os.listdir('.')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing a directory with `os.listdir`\n",
    "import os\n",
    "\n",
    "files = os.scandir('.')\n",
    "[file.name for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all files that end with .html\n",
    "import os\n",
    "import re\n",
    "\n",
    "files = os.scandir('.')\n",
    "[file.name for file in files if file.is_file() & (re.match('^.*\\.html', file.name) is not None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all files using glob\n",
    "from glob import glob\n",
    "\n",
    "files = glob('*')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all .html files using glob\n",
    "from glob import glob\n",
    "\n",
    "glob('*.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all .html files in all sub-directories\n",
    "import os\n",
    "import re\n",
    "\n",
    "def get_html_files(folder):\n",
    "    # Get all entries in current folder\n",
    "    entries = os.scandir(folder)\n",
    "    # Prepare a list that will store all .html files found in current folder\n",
    "    files = []\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            # If current entry is a directory, call `get_html_files` on the sub-directory\n",
    "            files.extend(get_html_files(entry.path))\n",
    "        elif entry.is_file():\n",
    "            # If current entry is a file, check if it ends with .html\n",
    "            # If yes, append it to the `files` list\n",
    "            if re.match('.*\\.html', entry.name) is not None:\n",
    "                files.append(entry.path)\n",
    "                \n",
    "    # And return all .html files found in current folder\n",
    "    return files\n",
    "\n",
    "get_html_files('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# `**` specifies to glob that it should match any folder or sub-folder\n",
    "glob('**/*.html', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and write two lines into it\n",
    "f = open('file.txt', 'w')\n",
    "f.write('This is some text')\n",
    "f.write('\\n')\n",
    "f.write('This is some text on next line')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .read returns the contents of the whole file as a string\n",
    "\n",
    "f = open('file.txt', 'r')\n",
    "f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .readlines returns the contents of the whole file split by lines as a list\n",
    "\n",
    "f = open('file.txt', 'r')\n",
    "f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .readline returns the current line as a string\n",
    "\n",
    "f = open('file.txt', 'r')\n",
    "f.readline()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentially, .read().split('\\n') returns .readlines()\n",
    "\n",
    "f = open('file.txt', 'r')\n",
    "f.read().split('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file with .with\n",
    "\n",
    "with open('file.txt', 'r') as f:\n",
    "    f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and parsing a CSV this way is annoyingly long\n",
    "import numpy as np\n",
    "\n",
    "first_line = True\n",
    "with open('df_example.csv', 'r') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        if first_line is True:\n",
    "            first_line = False\n",
    "        else:\n",
    "            data.append([float(n) for n in line.split(',')])\n",
    "    \n",
    "data = np.array(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series and DataFremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('df_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.Series example\n",
    "\n",
    "pd.Series([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame example\n",
    "\n",
    "pd.DataFrame([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame from multiple pandas.Series\n",
    "s1 = pd.Series([1, 2, 3])\n",
    "s2 = pd.Series([4, 5, 6])\n",
    "\n",
    "pd.DataFrame([s1, s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame with named rows and columns using `index` and `columns`\n",
    "pd.DataFrame(\n",
    "    [[1, 2, 3], [4, 5, 6]],\n",
    "    index=['row1', 'row2'],\n",
    "    columns=['col1', 'col2', 'col3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame with named rows and columns using a dictionary\n",
    "pd.DataFrame(\n",
    "    {'col1': {\n",
    "        'row1': 1, \n",
    "        'row2': 2, \n",
    "        'row3': 3\n",
    "    }, \n",
    "     'col2': {\n",
    "        'row1': 4, \n",
    "        'row2': 5, \n",
    "        'row3':6}\n",
    "    },\n",
    ")\n",
    "\n",
    "# A little more practical is to specify just the columns and pass the index\n",
    "pd.DataFrame(\n",
    "    {'col1': [1, 2, 3], 'col2': [4, 5, 6]},\n",
    "    index=['row1', 'row2', 'row3']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're gonna be using this example DataFrame for the next examples\n",
    "df = pd.read_csv('df_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A preview of a DataFrame using .head and .tail\n",
    "\n",
    "df.head()\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the rows and columns\n",
    "\n",
    "df.index\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesing data using the bracket notation\n",
    "\n",
    "# Column called `dim_1`\n",
    "df['dim_1']\n",
    "\n",
    "# Column called `dim_1`, first row\n",
    "df['dim_1'][0]\n",
    "\n",
    "# Columns called `dim_1` and `dim_2`\n",
    "df[['dim_1', 'dim_2']]\n",
    "\n",
    "# Columns called `dim_1` and `dim_2`, first row\n",
    "df[['dim_1', 'dim_2']][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesing data using .loc\n",
    "\n",
    "# Column called `dim_1`\n",
    "df.loc[:, 'dim_1']\n",
    "\n",
    "# Column called `dim_1`, first row\n",
    "df.loc[0, 'dim_1']\n",
    "\n",
    "# Columns called `dim_1` and `dim_2`\n",
    "df.loc[:, ['dim_1', 'dim_2']]\n",
    "\n",
    "# Columns called `dim_1` and `dim_2`, first row\n",
    "df.loc[0, ['dim_1', 'dim_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesing data using .iloc\n",
    "\n",
    "# Second column\n",
    "df.iloc[:, 1]\n",
    "\n",
    "# First row, second column\n",
    "df.iloc[0, 1]\n",
    "\n",
    "# Second and third column\n",
    "df.iloc[:, [1, 2]]\n",
    "\n",
    "# First row, second and third column\n",
    "df.iloc[0, [1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions return a boolean mask...\n",
    "\n",
    "df > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...which can be further use to filter out values\n",
    "\n",
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering done with columns will completely drop rows that do not meet the condition\n",
    "\n",
    "df[df['dim_0'] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing can also be used for setting a value\n",
    "\n",
    "df[df > 0] = 10\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also search if given columns contains a value from a list...\n",
    "\n",
    "df['text'] = np.random.choice(['one', 'two', 'three', 'four', 'five'], 100)\n",
    "df[df['text'].isin(['one', 'two'])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or perform string operations on the whole column\n",
    "\n",
    "df[df['text'].str.startswith('t')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can also filter by multiple conditions\n",
    "\n",
    "df[\n",
    "    (df['text']).isin(['one', 'two']) &\n",
    "    (df['dim_0'] > -1) &\n",
    "    (df['dim_5'] < -1)\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_example.csv')\n",
    "\n",
    "df = df[df < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what cells contain a missing value\n",
    "\n",
    "df.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all rows that contain a missing value\n",
    "\n",
    "df[df.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that contain a cell with missing value\n",
    "\n",
    "df.dropna(axis=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that contain a cell with missing value\n",
    "\n",
    "df.dropna(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values with a zero\n",
    "\n",
    "df.fillna(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values the previous one\n",
    "\n",
    "df.fillna(method='ffill', axis=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearly interpolate missing values\n",
    "\n",
    "df.interpolate().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping elements that are of undesider data type\n",
    "\n",
    "df.loc[1, 'dim_1'] = 'some_text'\n",
    "\n",
    "def drop_undesired_types(df, dtype_to_drop, axis=0):\n",
    "    t = dtype_to_drop if type(dtype_to_drop) == list else [dtype_to_drop]\n",
    "    return df.applymap(lambda x: None if type(x) in t else x).dropna(axis=axis)\n",
    "\n",
    "drop_undesired_types(df, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing large amount of data using chunksize\n",
    "\n",
    "i = 0\n",
    "for chunk in pd.read_csv('df_example.csv', chunksize=10):\n",
    "    i += 1\n",
    "    print(f\"Chunk {i}: {chunk['dim_1'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_example.csv')\n",
    "df['text'] = np.random.choice(['one', 'two', 'three', 'four', 'five'], 100)\n",
    "df['binary_category'] = np.random.choice([0, 1], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of each group\n",
    "\n",
    "df.groupby('text').agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby over multiple columns and calculate multiple stats\n",
    "\n",
    "df.groupby(['binary_category', 'text']).agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide custom function to `agg`\n",
    "\n",
    "df.groupby(['binary_category', 'text']).agg({\n",
    "    'dim_1': lambda x: np.sum(np.round(x)**3),\n",
    "    'dim_2': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate rows and reset index\n",
    "df1 = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\n",
    "df2 = pd.DataFrame([[7, 8, 9]])\n",
    "\n",
    "pd.concat((df1, df2)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join two dataframes based on key\n",
    "df1 = pd.DataFrame([[1, 2, \"one\"], [4, 5, \"two\"]])\n",
    "df2 = pd.DataFrame([[7, 8, \"one\"]])\n",
    "\n",
    "pd.merge(df1, df2, on=2, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('example.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('DROP TABLE IF EXISTS example_table')\n",
    "c.execute('CREATE TABLE example_table (dim_1 real, dim_2 real)')\n",
    "c.executemany('INSERT INTO example_table VALUES (?, ?)', np.random.randn(100, 2))\n",
    "\n",
    "for row in c.execute('SELECT * FROM example_table ORDER BY dim_1 DESC'):\n",
    "    print(f'{row[0]:.2f}', end=' ')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for a rectangle\n",
    "# Requires two attributes to construct an object: lengths of the two sides\n",
    "class Rectangle:\n",
    "    shape = \"rectangle\"\n",
    "    \n",
    "    def __init__(self, a, b):\n",
    "        print(f\"You created a {self.shape} with sides a = {a} and b = {b}\")\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def calc_perimeter(self):\n",
    "        return 2*self.a+2*self.b\n",
    "    \n",
    "    def calc_area(self):\n",
    "        return self.a*self.b\n",
    "    \n",
    "    #def __str__(self):\n",
    "    #    return f\"{self.shape}(a = {self.a}, b = {self.b})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = Rectangle(4, 5)\n",
    "print(f'a = {r1.a} and b = {r1.b}')\n",
    "print(f'perimeter = {r1.calc_perimeter()}')\n",
    "print(f'are = {r1.calc_area()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The textual representation of an object is not very nice, but that can be adjusted using the __str__ method\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square inherits the attributes of rectangle\n",
    "# We don't have to implement the methods again\n",
    "class Square(Rectangle):\n",
    "    shape = \"square\"\n",
    "    \n",
    "    def __init__(self, a):\n",
    "        # Square is a rectangle with both sides equal\n",
    "        # Therefore we just construct this as a Rectangle with the same argument twice\n",
    "        return super().__init__(a, a)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return super().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Square(4)\n",
    "s1.calc_perimeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also override methods to be able to perform mathematical operations\n",
    "class Rectangle:\n",
    "    shape = \"rectangle\"\n",
    "    \n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def calc_perimeter(self):\n",
    "        return 2*self.a+2*self.b\n",
    "    \n",
    "    def calc_area(self):\n",
    "        return self.a*self.b\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Rectangle(self.a + other.a, self.b + other.b)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return Rectangle(self.a - other.a, self.b - other.b)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return Rectangle(self.a * other.a, self.b * other.b)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.shape}(a = {self.a}, b = {self.b})\"\n",
    "    \n",
    "r1 = Rectangle(5, 9)\n",
    "r2= Rectangle(3, 5)\n",
    "\n",
    "print(r1 + r2)\n",
    "print(r1 - r2)\n",
    "print(r1 * r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, two objects are never equal\n",
    "r1 = Rectangle(0, 0)\n",
    "r2 = Rectangle(0, 0)\n",
    "r1 == r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, we can override the default function that checks for equality\n",
    "class Rectangle:   \n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def calc_perimeter(self):\n",
    "        return 2*self.a+2*self.b\n",
    "    \n",
    "    def calc_area(self):\n",
    "        return self.a*self.b\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.a == other.a and self.b == other.b\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.shape}(a = {self.a}, b = {self.b})\"\n",
    "    \n",
    "r1 = Rectangle(0, 0)\n",
    "r2 = Rectangle(0, 0)\n",
    "r1 == r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
